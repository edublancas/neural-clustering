{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neural_clustering.explorer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49a7279ee051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from neural_clustering.explorer import (SpikeTrainExplorer,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                         RecordingExplorer)\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_clustering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neural_clustering.explorer'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from yass.neuralnet import NeuralNetDetector\n",
    "from yass.config import Config\n",
    "\n",
    "from neural_clustering.explore import (SpikeTrainExplorer,\n",
    "                                       RecordingExplorer)\n",
    "from neural_clustering import config\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading configuration files and YASS output\n",
    "\n",
    "YASS is a Python package for spike sorting, which is being developed by Peter Lee (PhD in the Stats department and me): https://github.com/paninski-lab/yass\n",
    "\n",
    "Someone in the lab implemented a truncated DPMM using numpy. Since the code is hard to debug and the only person who understands it is the person who wrote it, I want to see if we can start using Edward instead, so we can iterate quickly and prototype new models easily â€“ without having to write custom inference algorithms every time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configuration files\n",
    "cfg_yass = Config.from_yaml('../yass_config/local_7ch.yaml')\n",
    "cfg = config.load('../config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data generated from yass\n",
    "files = ['score', 'clear_index', 'spike_times', 'spike_train', 'spike_left', 'templates']\n",
    "\n",
    "(score, clear_index,\n",
    " spike_times, spike_train,\n",
    " spike_left, templates) = [np.load(os.path.join(cfg['root'], 'yass/{}.npy'.format(f))) for f in  files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw recordings, geometry file and projection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw recordings\n",
    "path_to_raw_recordings = os.path.join(cfg_yass.root, '7ch.bin')\n",
    "# load standarized recordings (these are raw recordings + filter + standarization)\n",
    "path_to_recordings = os.path.join(cfg_yass.root, 'tmp/standarized.bin')\n",
    "# load gemetry file (position for every electro)\n",
    "path_to_geometry = os.path.join(cfg_yass.root, cfg_yass.geomFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load projection matrix (to reduce dimensionality)\n",
    "proj = NeuralNetDetector(cfg_yass).load_w_ae()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize explorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize explorers, these objects implement functions for plotting\n",
    "# the output from YASS\n",
    "explorer_rec = RecordingExplorer(path_to_recordings,\n",
    "                                 path_to_geometry,\n",
    "                                 dtype='float64',\n",
    "                                 window_size=cfg_yass.spikeSize,\n",
    "                                 n_channels=cfg_yass.nChan,\n",
    "                                 neighbor_radius=cfg_yass.spatialRadius)\n",
    "\n",
    "explorer_raw = RecordingExplorer(path_to_raw_recordings,\n",
    "                                 path_to_geometry,\n",
    "                                 dtype='int16',\n",
    "                                 window_size=cfg_yass.spikeSize,\n",
    "                                 n_channels=cfg_yass.nChan,\n",
    "                                 neighbor_radius=cfg_yass.spatialRadius)\n",
    "\n",
    "\n",
    "explorer_train = SpikeTrainExplorer(templates,\n",
    "                                    spike_train,\n",
    "                                    explorer_rec,\n",
    "                                    proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observations: {}. Channels: {}'.format(*explorer_raw.data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (60, 60)\n",
    "explorer_raw.plot_series(from_time=4500, to_time=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered + Standarized Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explorer_rec.plot_series(from_time=4500, to_time=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "explorer_rec.plot_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load clear spike times in channel 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_indexes = clear_index[0]\n",
    "clear_spikes = spike_times[0][clear_indexes, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_times = np.vstack(spike_times)[:, 0]\n",
    "print('Detected {} clear spikes'.format(clear_spikes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some errors here.... check\n",
    "# all_spike_times = np.sort(all_spike_times)[:-6]\n",
    "# there is a bug in the latest version of yass that shifts spike times...\n",
    "clear_spikes = clear_spikes - cfg_yass.BUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing a detected spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 15)\n",
    "t = clear_spikes[0]\n",
    "explorer_rec.plot_waveform(time=t, channels=range(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load waveforms around spike times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = explorer_rec.read_waveforms(times=clear_spikes)\n",
    "print('Training set dimensions: {}'.format(waveforms.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce waveforms temporal dimensionality from 31 to 3 and flatten data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms_reduced = explorer_train._reduce_dimension(waveforms, flatten=True)\n",
    "print('Training set dimensions: {}'.format(waveforms_reduced.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(cfg['root'], 'training.npy')\n",
    "np.save(output_path, waveforms_reduced)\n",
    "print(f'Saved training data in {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
